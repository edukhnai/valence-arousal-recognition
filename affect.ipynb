{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "affect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih3SbHcJmD3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow\n",
        "from PIL import ImageFile, Image\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization, LSTM, TimeDistributed, SpatialDropout1D\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oynzmja2nb2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYCPxpVRsKmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image size\n",
        "img_width, img_height = 148, 148\n",
        "# Ð grayscale image 148x148\n",
        "# backend Tensorflow => channels_last\n",
        "input_shape = (img_width, img_height, 1)\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Xh_v1xrI8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filling object-feature matrix\n",
        "X = []\n",
        "filenames = []\n",
        "c = 0\n",
        "for filename in sorted(glob.glob('/content/drive/My Drive/train/*.jpg')):\n",
        "  image = cv2.imread(filename)\n",
        "  image = cv2.resize(image, (img_width, img_height))\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  filenames.append(filename)\n",
        "  X.append(image)\n",
        "  c += 1\n",
        "  print(c)\n",
        "print(X[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhcevA07EVVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for filename in sorted(glob.glob('/content/drive/My Drive/train/*.jpg')):\n",
        "#   image = cv2.imread(filename)\n",
        "#   image = cv2.resize(image, (img_width, img_height))\n",
        "#   image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#   print(cv2_imshow(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyYRTZxRueHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting pixels values to range [0;1]\n",
        "X = np.divide(X, 255.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGQnGTNLnkec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading file with answers for images \n",
        "Y = pd.read_csv('/content/drive/My Drive/training.csv', sep=',')\n",
        "Y = Y[['subDirectory_filePath', 'valence', 'arousal']]\n",
        "Y['subDirectory_filePath'] = Y['subDirectory_filePath'].apply(lambda x: x.split(\"/\")[1])\n",
        "Y = Y.sort_values('subDirectory_filePath')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xo-9Z1WFqj1",
        "colab_type": "code",
        "outputId": "9ad5d484-9571-4489-abd5-fa9f9a359db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subDirectory_filePath</th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34738</th>\n",
              "      <td>0000792211b64f6a59bd2d95fee49eabe6373ec1d88f22...</td>\n",
              "      <td>-0.488145</td>\n",
              "      <td>0.821877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157036</th>\n",
              "      <td>0000f8a4575c15055a9ee0a72c9aa5bf9ac00558173565...</td>\n",
              "      <td>-0.316056</td>\n",
              "      <td>-0.136957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26740</th>\n",
              "      <td>00012312112a15995f1d1c1ac640db7191eacab8099e90...</td>\n",
              "      <td>0.710109</td>\n",
              "      <td>0.689223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178824</th>\n",
              "      <td>0001636b7a16a63b2d9c8f5e4b7be02e4841d3e0af3ebd...</td>\n",
              "      <td>-0.420635</td>\n",
              "      <td>0.515873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298470</th>\n",
              "      <td>0001720743cf22095bd3b2c94b35f244faf47545e26168...</td>\n",
              "      <td>0.521274</td>\n",
              "      <td>0.126796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    subDirectory_filePath   valence   arousal\n",
              "34738   0000792211b64f6a59bd2d95fee49eabe6373ec1d88f22... -0.488145  0.821877\n",
              "157036  0000f8a4575c15055a9ee0a72c9aa5bf9ac00558173565... -0.316056 -0.136957\n",
              "26740   00012312112a15995f1d1c1ac640db7191eacab8099e90...  0.710109  0.689223\n",
              "178824  0001636b7a16a63b2d9c8f5e4b7be02e4841d3e0af3ebd... -0.420635  0.515873\n",
              "298470  0001720743cf22095bd3b2c94b35f244faf47545e26168...  0.521274  0.126796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOWVRwtBvCVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y1 = []\n",
        "# for index, row in Y.iterrows():\n",
        "#   for f in filenames:\n",
        "#     if f.find(row['subDirectory_filePath']) >= 0:\n",
        "#       Y1.append(row)\n",
        "#       print(\"appending \" + str(row))\n",
        "#       break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNjFsqGyiikz",
        "colab_type": "code",
        "outputId": "388e6f67-e573-4171-cd26-0a1ba59437c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/y_modified.csv', sep=',')\n",
        "df = df[['subDirectory_filePath', 'valence', 'arousal']]\n",
        "df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subDirectory_filePath</th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c10a8f6735212d71eb54298bc47ea56dc08e64ed2ca...</td>\n",
              "      <td>0.004313</td>\n",
              "      <td>-0.008627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001fffed9707757082906ff2eb89cad6ddf242195fe6a5...</td>\n",
              "      <td>0.539683</td>\n",
              "      <td>0.023810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>002b6db57713be4a264d8dd13ee543b031de7577af983c...</td>\n",
              "      <td>-0.193573</td>\n",
              "      <td>0.590399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003e5febbe7808b02f6cafe17878cdfd59851726451209...</td>\n",
              "      <td>0.526805</td>\n",
              "      <td>-0.036153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>004b10f6bfbce7f58d124ac653451bdd975a7113d20b18...</td>\n",
              "      <td>0.849206</td>\n",
              "      <td>0.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>7a2b38adf6aa2d7b8b93d02f5defb7a6aebd738f8e544e...</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>7a2e5d157c9cbe119103f1a60052350ef3cbd14f651628...</td>\n",
              "      <td>-0.111111</td>\n",
              "      <td>-0.920635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>7a7b4f6fb23aaa9189a6faf644d07780947b00048d6992...</td>\n",
              "      <td>0.552105</td>\n",
              "      <td>0.219979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2140</th>\n",
              "      <td>7a7ea6d03d1cf4275e6dfc6d26104467c079edccecfcb0...</td>\n",
              "      <td>0.711698</td>\n",
              "      <td>0.125086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2141</th>\n",
              "      <td>7a8a674ef4503df80778541cf1c92a91c67f5bfbd9f364...</td>\n",
              "      <td>0.635431</td>\n",
              "      <td>0.049763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2142 rows Ã 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  subDirectory_filePath   valence   arousal\n",
              "0     000c10a8f6735212d71eb54298bc47ea56dc08e64ed2ca...  0.004313 -0.008627\n",
              "1     001fffed9707757082906ff2eb89cad6ddf242195fe6a5...  0.539683  0.023810\n",
              "2     002b6db57713be4a264d8dd13ee543b031de7577af983c... -0.193573  0.590399\n",
              "3     003e5febbe7808b02f6cafe17878cdfd59851726451209...  0.526805 -0.036153\n",
              "4     004b10f6bfbce7f58d124ac653451bdd975a7113d20b18...  0.849206  0.238095\n",
              "...                                                 ...       ...       ...\n",
              "2137  7a2b38adf6aa2d7b8b93d02f5defb7a6aebd738f8e544e...  0.380952  0.063492\n",
              "2138  7a2e5d157c9cbe119103f1a60052350ef3cbd14f651628... -0.111111 -0.920635\n",
              "2139  7a7b4f6fb23aaa9189a6faf644d07780947b00048d6992...  0.552105  0.219979\n",
              "2140  7a7ea6d03d1cf4275e6dfc6d26104467c079edccecfcb0...  0.711698  0.125086\n",
              "2141  7a8a674ef4503df80778541cf1c92a91c67f5bfbd9f364...  0.635431  0.049763\n",
              "\n",
              "[2142 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK2mhJL34IT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenation filenames with X matrix\n",
        "d = dict(zip(filenames, X))\n",
        "list(d.keys())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBPtOrbVgoUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = df['subDirectory_filePath']\n",
        "new_dict = {}\n",
        "for key in d.keys():\n",
        "  for file in files:\n",
        "    if key.find(file) >= 0:\n",
        "      new_dict.update({key:d[key]})\n",
        "      break\n",
        "print(len(new_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHI2WOXltMT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['image'] = list(new_dict.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTnWoxrJuvpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes_to_drop = df[(df['valence'] == -2) | (df['arousal'] == -2)].index\n",
        "df.drop(indexes_to_drop, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqoyXozEx2fZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "e605a457-72de-4671-f1cf-ce68ca7888a3"
      },
      "source": [
        "# common model for both valence and arousal\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 148, 148, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 146, 146, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 69, 69, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 30, 30, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 13, 13, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 150)               960150    \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 2,131,981\n",
            "Trainable params: 2,131,981\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAPzVZfWD97X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# valence training\n",
        "x_train_v, x_test_v, y_train_v, y_test_v = train_test_split(np.stack(list(df['image']), axis=0), list(df['valence']), test_size=0.33)\n",
        "\n",
        "x_train_v = x_train_v.reshape(x_train_v.shape[0], img_width, img_height, 1)\n",
        "x_test_v = x_test_v.reshape(x_test_v.shape[0], img_width, img_height, 1)\n",
        "\n",
        "model_v.fit(x_train_v, y_train_v, epochs=100, batch_size=64, validation_data=(x_test_v, y_test_v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsrmWRYxbRCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arousal training\n",
        "x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(np.stack(list(df['image']), axis=0), list(df['arousal']), test_size=0.33)\n",
        "\n",
        "x_train_a = x_train_a.reshape(x_train_a.shape[0], img_width, img_height, 1)\n",
        "x_test_a = x_test_a.reshape(x_test_a.shape[0], img_width, img_height, 1)\n",
        "\n",
        "model_a.fit(x_train_a, y_train_a, epochs=100, batch_size=128, validation_data=(x_test_a, y_test_a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj3blHaFSQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"score = \" + str(1 - model_v.evaluate(x_test_v, y_test_v)[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUHJyLJXSM1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving valence model to file\n",
        "model_json_v = model_v.to_json()\n",
        "\n",
        "json_file = open(\"affect_model_v.json\", \"w\")\n",
        "json_file.write(model_json_v)\n",
        "json_file.close()\n",
        "\n",
        "model_v.save_weights(\"affect_model_v.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQjAoElpbb65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving arousal model to file\n",
        "model_json_a = model_a.to_json()\n",
        "\n",
        "json_file = open(\"affect_model_a.json\", \"w\")\n",
        "json_file.write(model_json_a)\n",
        "json_file.close()\n",
        "\n",
        "model_a.save_weights(\"affect_model_a.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B775mvXQbm02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate script for emotion recognition \n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "import argparse as ar\n",
        "\n",
        "parser = ar.ArgumentParser()\n",
        "parser.add_argument('path', metavar='path', type=str, nargs='+', help='an integer for the accumulator')\n",
        "img_path = parser.parse_args().path[0]\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x /= 255\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "json_file_v = open(\"affect_model_v.json\", \"r\")\n",
        "json_file_a = open(\"affect_model_a.json\", \"r\")\n",
        "\n",
        "loaded_model_json_v = json_file_v.read()\n",
        "loaded_model_json_a = json_file_a.read()\n",
        "\n",
        "json_file_v.close()\n",
        "json_file_a.close()\n",
        "\n",
        "loaded_model_v = model_from_json(loaded_model_json_v)\n",
        "loaded_model_a = model_from_json(loaded_model_json_a)\n",
        "\n",
        "loaded_model_v.load_weights(\"affect_model_v.h5\")\n",
        "loaded_model_a.load_weights(\"affect_model_a.h5\")\n",
        "\n",
        "loaded_model_v.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "loaded_model_a.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "prediction_v = loaded_model_v.predict(x)\n",
        "prediction_a = loaded_model_a.predict(x)\n",
        "\n",
        "if prediction_v >= -0.5 and prediction_v <= 0.5 and prediction_a <= -0.66:\n",
        "    print(\"focus\")\n",
        "elif prediction_v >= -0.2 and prediction_a >= -0.66 and prediction_a <= 0:\n",
        "    print(\"relaxation\")\n",
        "elif prediction_v <= 0 and prediction_a <= 0:\n",
        "    print(\"stress\")\n",
        "elif prediction_v >= 0 and prediction_v <= 0.4 and prediction_a >= 0 and prediction_a <= 0.4:\n",
        "    print(\"interest\")\n",
        "elif (prediction_v >= 0 and prediction_v <= 0.7 and prediction_a >= 0.4 and prediction_a <= 0.7 or\n",
        "      prediction_v >= 0.4 and prediction_v <= 0.7 and prediction_a >= 0 and prediction_a <= 0.4 or\n",
        "      prediction_v >= 0.7 and prediction_v <= 1 and prediction_a >= 0 and prediction_a <= 1):\n",
        "    print(\"engagement\")\n",
        "elif prediction_v >= 0 and prediction_v <= 1 and prediction_a >= 0.7 and prediction_a <= 1:\n",
        "    print(\"excitement\")\n",
        "else:\n",
        "    print(\"Cannot determine emotion\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}